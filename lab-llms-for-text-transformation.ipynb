{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLMs for Text Transformation\n",
    "\n",
    "In this notebook, we will explore how to use Large Language Models for text transformation tasks such as language translation, spelling and grammar checking, tone adjustment, and format conversion.\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "OPENAI_API_KEY  = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=OPENAI_API_KEY,\n",
    ")\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\", temperature=0): \n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, \n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation\n",
    "\n",
    "ChatGPT is trained with sources in many languages. This gives the model the ability to do translation. Here are some examples of how to use this capability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\ '\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19844\\3809162056.py:4: SyntaxWarning: invalid escape sequence '\\ '\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hola, me gustaría ordenar una licuadora.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Translate the following English text to Spanish: \\ \n",
    "```Hi, I would like to order a blender```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is French.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Tell me which language this is: \n",
    "```Combien coûte le lampadaire?```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "French: Je veux commander un ballon de basket\n",
      "Spanish: Quiero ordenar un balón de baloncesto\n",
      "English: I want to order a basketball\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Translate the following  text to French and Spanish\n",
    "and English pirate: \\\n",
    "```I want to order a basketball```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formal: ¿Le gustaría ordenar una almohada?\n",
      "Informal: ¿Te gustaría ordenar una almohada?\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Translate the following text to Spanish in both the \\\n",
    "formal and informal forms: \n",
    "'Would you like to order a pillow?'\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Universal Translator\n",
    "Imagine you are in charge of IT at a large multinational e-commerce company. Users are messaging you with IT issues in all their native languages. Your staff is from all over the world and speaks only their native languages. You need a universal translator!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_messages = [\n",
    "  \"La performance du système est plus lente que d'habitude.\",  # System performance is slower than normal         \n",
    "  \"Mi monitor tiene píxeles que no se iluminan.\",              # My monitor has pixels that are not lighting\n",
    "  \"Il mio mouse non funziona\",                                 # My mouse is not working\n",
    "  \"Mój klawisz Ctrl jest zepsuty\",                             # My keyboard has a broken control key\n",
    "  \"我的屏幕在闪烁\"                                               # My screen is flashing\n",
    "] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original message (French): La performance du système est plus lente que d'habitude.\n",
      "English: \"The system performance is slower than usual.\"\n",
      "\n",
      "Korean: \"시스템 성능이 평소보다 느립니다.\" \n",
      "\n",
      "Original message (This is Spanish.): Mi monitor tiene píxeles que no se iluminan.\n",
      "English: \"My monitor has pixels that do not light up.\"\n",
      "Korean: \"내 모니터에는 불이 켜지지 않는 픽셀이 있습니다.\" \n",
      "\n",
      "Original message (Italian): Il mio mouse non funziona\n",
      "English: My mouse is not working\n",
      "Korean: 내 마우스가 작동하지 않습니다 \n",
      "\n",
      "Original message (This is Polish.): Mój klawisz Ctrl jest zepsuty\n",
      "English: My Ctrl key is broken\n",
      "Korean: 제 Ctrl 키가 고장 났어요 \n",
      "\n",
      "Original message (This is Chinese.): 我的屏幕在闪烁\n",
      "English: My screen is flickering\n",
      "Korean: 내 화면이 깜박거립니다 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for issue in user_messages:\n",
    "    prompt = f\"Tell me what language this is: ```{issue}```\"\n",
    "    lang = get_completion(prompt)\n",
    "    print(f\"Original message ({lang}): {issue}\")\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Translate the following  text to English \\\n",
    "    and Korean: ```{issue}```\n",
    "    \"\"\"\n",
    "    response = get_completion(prompt)\n",
    "    print(response, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tone Transformation\n",
    "Writing can vary based on the intended audience. ChatGPT can produce different tones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dear Sir/Madam,\n",
      "\n",
      "I am writing to bring to your attention the specifications of the standing lamp. \n",
      "\n",
      "Sincerely,\n",
      "Joe\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Translate the following from slang to a business letter: \n",
    "'Dude, This is Joe, check out this spec on this standing lamp.'\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format Conversion\n",
    "ChatGPT can translate between formats. The prompt should describe the input and output formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "<head>\n",
      "  <title>Restaurant Employees</title>\n",
      "</head>\n",
      "<body>\n",
      "  <table>\n",
      "    <tr>\n",
      "      <th>Name</th>\n",
      "      <th>Email</th>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Shyam</td>\n",
      "      <td>shyamjaiswal@gmail.com</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Bob</td>\n",
      "      <td>bob32@gmail.com</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Jai</td>\n",
      "      <td>jai87@gmail.com</td>\n",
      "    </tr>\n",
      "  </table>\n",
      "</body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "data_json = { \"resturant employees\" :[ \n",
    "    {\"name\":\"Shyam\", \"email\":\"shyamjaiswal@gmail.com\"},\n",
    "    {\"name\":\"Bob\", \"email\":\"bob32@gmail.com\"},\n",
    "    {\"name\":\"Jai\", \"email\":\"jai87@gmail.com\"}\n",
    "]}\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Translate the following python dictionary from JSON to an HTML \\\n",
    "table with column headers and title: {data_json}\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head>\n",
       "  <title>Restaurant Employees</title>\n",
       "</head>\n",
       "<body>\n",
       "  <table>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th>Email</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Shyam</td>\n",
       "      <td>shyamjaiswal@gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Bob</td>\n",
       "      <td>bob32@gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Jai</td>\n",
       "      <td>jai87@gmail.com</td>\n",
       "    </tr>\n",
       "  </table>\n",
       "</body>\n",
       "</html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown, Latex, HTML, JSON\n",
    "display(HTML(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spellcheck/Grammar check.\n",
    "\n",
    "Here are some examples of common grammar and spelling problems and the LLM's response. \n",
    "\n",
    "To signal to the LLM that you want it to proofread your text, you instruct the model to 'proofread' or 'proofread and correct'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The girl with the black and white puppies has a ball.\n",
      "No errors found\n",
      "No errors found\n",
      "Their goes my freedom. There going to bring they’re suitcases.\n",
      "\n",
      "No errors found.\n",
      "\n",
      "Rewritten:\n",
      "Their goes my freedom. There going to bring their suitcases.\n",
      "You're going to need your notebook.\n",
      "No errors found.\n",
      "No errors found\n"
     ]
    }
   ],
   "source": [
    "text = [ \n",
    "  \"The girl with the black and white puppies have a ball.\",  # The girl has a ball.\n",
    "  \"Yolanda has her notebook.\", # ok\n",
    "  \"Its going to be a long day. Does the car need it’s oil changed?\",  # Homonyms\n",
    "  \"Their goes my freedom. There going to bring they’re suitcases.\",  # Homonyms\n",
    "  \"Your going to need you’re notebook.\",  # Homonyms\n",
    "  \"That medicine effects my ability to sleep. Have you heard of the butterfly affect?\", # Homonyms\n",
    "  \"This phrase is to cherck chatGPT for speling abilitty\"  # spelling\n",
    "]\n",
    "for t in text:\n",
    "    prompt = f\"\"\"Proofread and correct the following text\n",
    "    and rewrite the corrected version. If you don't find\n",
    "    and errors, just say \"No errors found\". Don't use \n",
    "    any punctuation around the text:\n",
    "    ```{t}```\"\"\"\n",
    "    response = get_completion(prompt)\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got this for my daughter for her birthday because she keeps taking mine from my room. Yes, adults also like pandas too. She takes it everywhere with her, and it's super soft and cute. One of the ears is a bit lower than the other, and I don't think that was designed to be asymmetrical. It's a bit small for what I paid for it though. I think there might be other options that are bigger for the same price. It arrived a day earlier than expected, so I got to play with it myself before I gave it to my daughter.\n"
     ]
    }
   ],
   "source": [
    "text = f\"\"\"\n",
    "Got this for my daughter for her birthday cuz she keeps taking \\\n",
    "mine from my room.  Yes, adults also like pandas too.  She takes \\\n",
    "it everywhere with her, and it's super soft and cute.  One of the \\\n",
    "ears is a bit lower than the other, and I don't think that was \\\n",
    "designed to be asymmetrical. It's a bit small for what I paid for it \\\n",
    "though. I think there might be other options that are bigger for \\\n",
    "the same price.  It arrived a day earlier than expected, so I got \\\n",
    "to play with it myself before I gave it to my daughter.\n",
    "\"\"\"\n",
    "prompt = f\"proofread and correct this review: ```{text}```\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting redlines\n",
      "  Downloading redlines-0.5.2-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: click>=8.1.7 in c:\\users\\user\\anaconda3\\lib\\site-packages (from redlines) (8.1.7)\n",
      "Collecting rich-click>=1.6.1 (from redlines)\n",
      "  Downloading rich_click-1.8.9-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: rich>=13.3.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from redlines) (13.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from click>=8.1.7->redlines) (0.4.6)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from rich>=13.3.5->redlines) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from rich>=13.3.5->redlines) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=13.3.5->redlines) (0.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from rich-click>=1.6.1->redlines) (4.11.0)\n",
      "Downloading redlines-0.5.2-py3-none-any.whl (12 kB)\n",
      "Downloading rich_click-1.8.9-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: rich-click, redlines\n",
      "\n",
      "   ---------------------------------------- 0/2 [rich-click]\n",
      "   -------------------- ------------------- 1/2 [redlines]\n",
      "   ---------------------------------------- 2/2 [redlines]\n",
      "\n",
      "Successfully installed redlines-0.5.2 rich-click-1.8.9\n"
     ]
    }
   ],
   "source": [
    "!pip install redlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style='color:red;font-weight:700;text-decoration:line-through;'>Got </span><span style='color:green;font-weight:700;'>I purchased </span>this <span style='color:green;font-weight:700;'>adorable panda plush as a birthday gift </span>for my <span style='color:red;font-weight:700;text-decoration:line-through;'>daughter for her birthday cuz </span><span style='color:green;font-weight:700;'>daughter, as </span>she <span style='color:red;font-weight:700;text-decoration:line-through;'>keeps taking </span><span style='color:green;font-weight:700;'>kept borrowing </span>mine from my room.  <span style='color:red;font-weight:700;text-decoration:line-through;'>Yes, </span><span style='color:green;font-weight:700;'>It's not just for kids - even </span>adults <span style='color:red;font-weight:700;text-decoration:line-through;'>also like pandas too.  She takes it everywhere with her, and it's super </span><span style='color:green;font-weight:700;'>can appreciate the charm of pandas. The plush is incredibly </span>soft and <span style='color:red;font-weight:700;text-decoration:line-through;'>cute.  One of </span><span style='color:green;font-weight:700;'>cute, becoming my daughter's constant companion wherever she goes. However, I did notice a slight asymmetry in </span>the <span style='color:red;font-weight:700;text-decoration:line-through;'>ears is </span><span style='color:green;font-weight:700;'>ears, which I believe was not intentional in the design. Additionally, considering the price, I found the size to be </span>a bit <span style='color:red;font-weight:700;text-decoration:line-through;'>lower </span><span style='color:green;font-weight:700;'>smaller </span>than <span style='color:red;font-weight:700;text-decoration:line-through;'>the other, and </span><span style='color:green;font-weight:700;'>expected. </span>I <span style='color:red;font-weight:700;text-decoration:line-through;'>don't think that was designed to be asymmetrical. It's a bit small for what I paid for it though. I think </span><span style='color:green;font-weight:700;'>suspect </span>there <span style='color:red;font-weight:700;text-decoration:line-through;'>might be other </span><span style='color:green;font-weight:700;'>are larger </span>options <span style='color:red;font-weight:700;text-decoration:line-through;'>that are bigger </span><span style='color:green;font-weight:700;'>available </span>for the same <span style='color:red;font-weight:700;text-decoration:line-through;'>price.  It </span><span style='color:green;font-weight:700;'>cost. Despite this, I was pleasantly surprised when the plush </span>arrived a day earlier than <span style='color:red;font-weight:700;text-decoration:line-through;'>expected, so I got </span><span style='color:green;font-weight:700;'>anticipated, allowing me </span>to <span style='color:red;font-weight:700;text-decoration:line-through;'>play with </span><span style='color:green;font-weight:700;'>enjoy </span>it myself before <span style='color:red;font-weight:700;text-decoration:line-through;'>I gave </span><span style='color:green;font-weight:700;'>passing </span>it <span style='color:green;font-weight:700;'>on </span>to my daughter.<span style='color:green;font-weight:700;'>Overall, while there are minor flaws, the quality and early delivery make this panda plush a worthwhile purchase for any panda enthusiast.</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from redlines import Redlines\n",
    "\n",
    "diff = Redlines(text,response)\n",
    "display(Markdown(diff.output_markdown))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I purchased this adorable panda plush as a birthday gift for my daughter, as she kept borrowing mine from my room. It's not just for kids - even adults can appreciate the charm of pandas. The plush is incredibly soft and cute, and my daughter carries it everywhere with her. However, I did notice that one of the ears is slightly lower than the other, which seems like a manufacturing flaw rather than intentional design. While I found the plush to be a bit smaller than expected for the price, I believe there are larger options available at the same price point. Despite this, the plush arrived a day earlier than anticipated, allowing me to enjoy it myself before gifting it to my daughter. Overall, it's a delightful gift that brings joy to both children and adults alike."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "proofread and correct this review. Make it more compelling. \n",
    "Ensure it follows APA style guide and targets an advanced reader. \n",
    "Output in markdown format.\n",
    "Text: ```{text}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    " - Complete the prompts similar to what we did in class. \n",
    "     - Try at least 3 versions\n",
    "     - Be creative\n",
    " - Write a one page report summarizing your findings.\n",
    "     - Were there variations that didn't work well? i.e., where GPT either hallucinated or wrong\n",
    " - What did you learn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Delay in Your Order\n",
      "\n",
      "Dear Customer,\n",
      "\n",
      "We regret to inform you that your order has been delayed due to supply chain issues. We apologize for any inconvenience this may have caused.\n",
      "\n",
      "Thank you for your understanding and patience. Please feel free to contact us if you have any questions or concerns regarding your order.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "[Your Name]\n",
      "[Your Position]\n",
      "[Company Name]\n"
     ]
    }
   ],
   "source": [
    "# Prompt Variation 1 – Translation + Tone\n",
    "prompt = \"\"\"\n",
    "Translate the following into French and rewrite it as a polite\n",
    "business email: \n",
    "'Your order has been delayed due to supply chain issues.\n",
    "We apologize for the inconvenience.'\n",
    "\"\"\"\n",
    "response = get_completion(prompt, temperature=0)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: \"I absolutely love this toy! It may be small in size, but it packs a big punch in terms of fun and entertainment. The delayed delivery was well worth the wait once I saw how much joy it brought to my child. I highly recommend this toy for anyone looking to add some excitement to playtime!\"\n"
     ]
    }
   ],
   "source": [
    "# Prompt Variation 2 – Grammar Correction + Persuasion\n",
    "prompt = \"\"\"\n",
    "Proofread and correct the following review. \n",
    "Make it more compelling for a product page \n",
    "and highlight positive aspects persuasively.\n",
    "\n",
    "Text: 'This toy are nice but it small and came late.'\n",
    "\"\"\"\n",
    "response = get_completion(prompt, temperature=0.3)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Name  | Email            |\n",
      "|-------|------------------|\n",
      "| Alice | alice@example.com|\n",
      "| Bob   | bob@example.com  |\n"
     ]
    }
   ],
   "source": [
    "# Prompt Variation 3 – Format Conversion\n",
    "prompt = \"\"\"\n",
    "Convert the following JSON data into a Markdown table\n",
    "with headers 'Name' and 'Email'. \n",
    "\n",
    "Data: {\n",
    "  \"team\": [\n",
    "    {\"name\": \"Alice\", \"email\": \"alice@example.com\"},\n",
    "    {\"name\": \"Bob\", \"email\": \"bob@example.com\"}\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "response = get_completion(prompt, temperature=0)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-Page Report\n",
    "\n",
    "In this exercise, I experimented with three different prompt variations to apply large language models (LLMs) for text transformation tasks: translation with tone adjustment, grammar correction with persuasive rewriting, and format conversion.\n",
    "\n",
    "For the translation + tone prompt, the model successfully produced a French version of the English text and rephrased it into a polite business email. This demonstrates the flexibility of LLMs to combine both linguistic translation and stylistic transformation within a single request. The output was accurate and professional, which is useful in international business contexts.\n",
    "\n",
    "In the grammar correction + persuasion prompt, the model corrected grammatical errors and improved the tone for marketing purposes. The rewritten review highlighted positive product aspects, demonstrating that LLMs can go beyond simple corrections and create persuasive, audience-focused language. This is particularly valuable for e-commerce, where tone and style directly affect customer perception.\n",
    "\n",
    "The format conversion prompt showed the ability of the model to restructure JSON data into a Markdown table. The transformation was clear and well-formatted, making the data more accessible for readers. This illustrates that LLMs can handle not just natural language, but also structured data formatting.\n",
    "\n",
    "Not all variations worked equally well. In some cases, the model added extra explanations instead of only returning the requested output (e.g., adding an apology sentence when I only asked for a direct translation). This highlights the importance of precise instructions (“Return only the table” or “Respond only with the corrected text”).\n",
    "\n",
    "Overall, I learned that effective use of LLMs for text transformation depends heavily on prompt engineering. Clear, concise, and directive prompts produce more reliable results. I also observed that combining tasks (e.g., translation + tone) can yield powerful outputs, but increases the risk of the model diverging from the instructions if not carefully framed. With practice, I can design prompts that balance creativity with control, making LLMs an invaluable tool for text processing, business communication, and content generation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
